{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flower Classification\n",
    "\n",
    "In this project I will be participating in the [Petals to the Metal](https://www.kaggle.com/c/tpu-getting-started/overview) competition, which is a \"getting started\" competition on [Kaggle](kaggle.com). The objective is to classify different flowers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "IMAGE_SIZE = [512, 512]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'.\\tfrecords-jpeg-512x512'\n",
    "TRAINING_FILENAMES = tf.io.gfile.glob(path + '/train/*.tfrec')\n",
    "VALIDATION_FILENAMES = tf.io.gfile.glob(path + '/val/*.tfrec')\n",
    "TEST_FILENAMES = tf.io.gfile.glob(path + '/test/*.tfrec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "These functions can be found in the `petal_helper.py` file. I will be re-making them here in an effort to understand what they do. These functions are primarily used to prepare the data for use by the tpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image_data):\n",
    "    '''Turn image data into an array of numbers\n",
    "    Args:\n",
    "        image_data: jpeg image extracted from a tfrecord file\n",
    "    Returns:\n",
    "        \n",
    "    '''\n",
    "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0 # convert image to floates in [0,1] range\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE , 3]) # explicit size needed for TPU\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string), # tf.string means bytesting\n",
    "        'class': tf.io.FixedLenFeature([], tf.int64) # shape[] means single element\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['class'], tf.int32)\n",
    "    return image, label\n",
    "\n",
    "def read_unlabeled_tfrecord(example):\n",
    "    UNLABELED_TFREC_FORMAT = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'id': tf.io.FixedLenFeature([], tf.string)\n",
    "        # no class, because this will be used on the test dataset\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames, labeled = True, ordered = False):\n",
    "    # Read from tfrecords. for optimal performance, reading from multiple files at once and disregarding\n",
    "    # data order. order does not mapper since we will be shuffling the data anyway\n",
    "    # it's generally a good idea to split the data into 16 parts when working with a tpu\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False #disable order use what is currently being loaded\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO) \n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord,\n",
    "                          num_parallel_calls = AUTO)\n",
    "    # returns a dataset of (image, label) pairs if labeled = True or (image, id) if not labeled\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParallelMapDataset shapes: ((512, 512, 3), ()), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset(TRAINING_FILENAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
