{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flower Classification\n",
    "\n",
    "In this project I will be participating in the [Petals to the Metal](https://www.kaggle.com/c/tpu-getting-started/overview) competition, which is a \"getting started\" competition on [Kaggle](kaggle.com). The objective is to classify different flowers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'strategy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2f738fcf184a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mAUTO\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_replicas_in_sync\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'strategy' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math, re, os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "IMAGE_SIZE = [512, 512]\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'.\\tfrecords-jpeg-512x512'\n",
    "TRAINING_FILENAMES = tf.io.gfile.glob(path + '/train/*.tfrec')\n",
    "VALIDATION_FILENAMES = tf.io.gfile.glob(path + '/val/*.tfrec')\n",
    "TEST_FILENAMES = tf.io.gfile.glob(path + '/test/*.tfrec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "These functions can be found in the `petal_helper.py` file. I will be re-making them here in an effort to understand what they do. These functions are primarily used to prepare the data for use by the TPU. With a TPU it is important to always keep it supplied with data to analyze, for this reason, the data is in the form of `tfrec` files, as opposed to the `jpeg` pictures and separate `csv` with the labels for the pictures. This data is divided into 16 `tfrec` files, meaning that they contain both the pictures and the labels if applicable (The holdout set contains the unique identifiers of the pictures). The TPU that is used has 8 distinct cores. It is recommended to split the dataset up into twice the number of TPU cores to maximize efficiency. In order to minimize loading times, the datasets are also loaded into \"close proximity\" to the TPU, meaning in the same bucket in google cloud services in this case. It will be interesting if data in the same configuration can be used on my gpus and if not what changes I will have to make to adapt the code. I would expect the code to possibly run smoothly on my big GPU (2080ti) and cause issues with my small GPU (1050ti) due to the much lower memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the datasets from the `tfrec` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image_data):\n",
    "    '''Turn image data into an array of numbers\n",
    "    Args:\n",
    "        image_data: jpeg image extracted from a tfrecord file\n",
    "    Returns:\n",
    "        tensor containing the data of the image\n",
    "        \n",
    "    '''\n",
    "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0 # convert image to floates in [0,1] range\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE , 3]) # explicit size needed for TPU\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string), # tf.string means bytesting\n",
    "        'class': tf.io.FixedLenFeature([], tf.int64) # shape[] means single element\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['class'], tf.int32)\n",
    "    return image, label\n",
    "\n",
    "def read_unlabeled_tfrecord(example):\n",
    "    UNLABELED_TFREC_FORMAT = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'id': tf.io.FixedLenFeature([], tf.string)\n",
    "        # no class, because this will be used on the test dataset\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    idnum = example['id']\n",
    "    return image, idnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames, labeled = True, ordered = False):\n",
    "    # Read from tfrecords. for optimal performance, reading from multiple files at once and disregarding\n",
    "    # data order. order does not mapper since we will be shuffling the data anyway\n",
    "    # it's generally a good idea to split the data into 16 parts when working with a tpu\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False #disable order use what is currently being loaded\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO) \n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord,\n",
    "                          num_parallel_calls = AUTO)\n",
    "    # returns a dataset of (image, label) pairs if labeled = True or (image, id) if not labeled\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParallelMapDataset shapes: ((512, 512, 3), ()), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset(TRAINING_FILENAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmenting the data\n",
    "\n",
    "In order to reduce overfitting a function will be created that will flip the images randomly. This could be \"augmented\" by additional operations like cutting or rotating the images later on to possibly increase accuracy.\n",
    "\n",
    "The `dataset.prefetch(AUTO)` in the following `get_training_dataset` function causes all of the data pipeline code to be execute on the cpu during gradient descent calculations on the TPU, this should cause the performance to not be impacted. It will be interesting to see if this also applies while running the code on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the Datasets for Training, Validation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES, labeled = True)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.repeat() #This makes the dataset repeat if needed to always fully utilize the TPU\n",
    "    dataset = dataset.shuffle(2048) #This shuffles the order of the datapoints in the dataset to combat overfitting\n",
    "    dataset = dataset.batch(BATCH_SIZE) # This sets the batch size used, probably needs to be adjusted wehn usingt the gpu\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next patch while trining (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(ordered = False):\n",
    "    dataset = load_dataset(VALIDATION_FILENAMES, labeled = True, ordered = ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "def get_test_dataset(ordered = False):\n",
    "    dataset = load_dataset(TEST_FILENAMES, labeled = False, ordered = ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
